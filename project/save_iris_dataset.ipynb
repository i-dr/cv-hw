{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cdfbcf9-bc4e-493a-8c1a-f5f461786425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CELL >>>> (0, 0)\u0007\n",
      "CELL >>>> (0, 1)\u0007\n",
      "CELL >>>> (0, 2)\u0007\n",
      "CELL >>>> (0, 3)\u0007\n",
      "CELL >>>> (0, 4)\u0007\n",
      "CELL >>>> (0, 5)\u0007\n",
      "CELL >>>> (0, 6)\u0007\n",
      "CELL >>>> (0, 7)\u0007\n",
      "CELL >>>> (0, 8)\u0007\n",
      "CELL >>>> (0, 9)\u0007\n",
      "CELL >>>> (1, 0)\u0007\n",
      "CELL >>>> (1, 1)\u0007\n",
      "CELL >>>> (1, 2)\u0007\n",
      "CELL >>>> (1, 3)\u0007\n",
      "CELL >>>> (1, 4)\u0007\n",
      "CELL >>>> (1, 5)\u0007\n",
      "CELL >>>> (1, 6)\u0007\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 75\u001b[39m\n\u001b[32m     73\u001b[39m frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n\u001b[32m     74\u001b[39m mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame_rgb)\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m result = \u001b[43mdetector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmp_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[38;5;66;03m# 2D array for save frame without RGB, only landmarks\u001b[39;00m\n\u001b[32m     78\u001b[39m frame_map = np.zeros((CAP_HEIGHT, CAP_WIDTH), dtype=np.uint8)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\py311\\Lib\\site-packages\\mediapipe\\tasks\\python\\vision\\face_landmarker.py:3141\u001b[39m, in \u001b[36mFaceLandmarker.detect\u001b[39m\u001b[34m(self, image, image_processing_options)\u001b[39m\n\u001b[32m   3118\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Performs face landmarks detection on the given image.\u001b[39;00m\n\u001b[32m   3119\u001b[39m \n\u001b[32m   3120\u001b[39m \u001b[33;03mOnly use this method when the FaceLandmarker is created with the image\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   3136\u001b[39m \u001b[33;03m  RuntimeError: If face landmarker detection failed to run.\u001b[39;00m\n\u001b[32m   3137\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3138\u001b[39m normalized_rect = \u001b[38;5;28mself\u001b[39m.convert_to_normalized_rect(\n\u001b[32m   3139\u001b[39m     image_processing_options, image, roi_allowed=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   3140\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m3141\u001b[39m output_packets = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_image_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   3142\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_IMAGE_IN_STREAM_NAME\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpacket_creator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3143\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_NORM_RECT_STREAM_NAME\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpacket_creator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_proto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3144\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnormalized_rect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_pb2\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3145\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3146\u001b[39m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3148\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_packets[_NORM_LANDMARKS_STREAM_NAME].is_empty():\n\u001b[32m   3149\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m FaceLandmarkerResult([], [], [])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\py311\\Lib\\site-packages\\mediapipe\\tasks\\python\\vision\\core\\base_vision_task_api.py:95\u001b[39m, in \u001b[36mBaseVisionTaskApi._process_image_data\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._running_mode != _RunningMode.IMAGE:\n\u001b[32m     91\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     92\u001b[39m       \u001b[33m'\u001b[39m\u001b[33mTask is not initialized with the image mode. Current running mode:\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     93\u001b[39m       + \u001b[38;5;28mself\u001b[39m._running_mode.name\n\u001b[32m     94\u001b[39m   )\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_runner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "\n",
    "# ========================\n",
    "# Setup \n",
    "# ========================\n",
    "GRID_SIZE = 10          # 10x10 клітинок\n",
    "SCREEN_W, SCREEN_H = 1366, 768  # Розмір екрану (для демонстрації клітинок)\n",
    "SAVE_DIR = \"./gaze_dataset\"\n",
    "\n",
    "CAP_WIDTH = 1280 # camera w\n",
    "CAP_HEIGHT = 720 # camera h\n",
    "\n",
    "# === Групи лендмарків FaceMesh (індекси) ===\n",
    "LEFT_EYE_IDX = [33, 133, 159, 145, 160, 161, 246]  \n",
    "LEFT_IRIS = [468, 469, 470, 471, 472]\n",
    "RIGHT_EYE_IDX = [362, 263, 386, 374, 385, 390, 466]\n",
    "RIGHT_IRIS = [473, 474, 475, 476, 477]\n",
    "REFERENCE_IDX = [1, 6, 168, 55, 285, 152, 234, 454]  # nose + brow + chin\n",
    "\n",
    "fixed_indices = LEFT_EYE_IDX + LEFT_IRIS + RIGHT_EYE_IDX + RIGHT_IRIS + REFERENCE_IDX\n",
    "\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# ========================\n",
    "# Init Mediapipe\n",
    "# ========================\n",
    "model_path = r\"./face_landmarker.task\"\n",
    "\n",
    "with open(model_path, \"rb\") as f:\n",
    "    model_buffer = f.read()\n",
    "\n",
    "# === Setup MediaPipe ===\n",
    "BaseOptions = mp.tasks.BaseOptions\n",
    "FaceLandmarker = mp.tasks.vision.FaceLandmarker\n",
    "FaceLandmarkerOptions = mp.tasks.vision.FaceLandmarkerOptions\n",
    "VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "\n",
    "options = FaceLandmarkerOptions(\n",
    "    base_options=BaseOptions(model_asset_buffer=model_buffer),\n",
    "    running_mode=VisionRunningMode.IMAGE,\n",
    "    num_faces=1,\n",
    ")\n",
    "detector = FaceLandmarker.create_from_options(options)\n",
    "\n",
    "\n",
    "\n",
    "# === Capture frames from webcam ===\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, CAP_WIDTH)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, CAP_HEIGHT)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Main collector of samples\n",
    "# =========================\n",
    "for row in range(GRID_SIZE):\n",
    "    for col in range(GRID_SIZE):\n",
    "        print(f\"CELL >>>> ({row}, {col})\")\n",
    "        # time coundown for 1 cell gaze\n",
    "        preview_time = 2.0  \n",
    "        start_time = time.time()\n",
    "\n",
    "        while time.time() - start_time < preview_time:\n",
    "            ret, frame = cap.read()\n",
    "            # cap.release()\n",
    "            if not ret:\n",
    "                continue\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame_rgb)\n",
    "            result = detector.detect(mp_image)\n",
    "\n",
    "            # 2D array for save frame without RGB, only landmarks\n",
    "            frame_map = np.zeros((CAP_HEIGHT, CAP_WIDTH), dtype=np.uint8)\n",
    "\n",
    "            if result.face_landmarks:\n",
    "                face = result.face_landmarks[0]\n",
    "                for idx in fixed_indices:\n",
    "                    lm = face[idx]\n",
    "                    x = int(lm.x * CAP_WIDTH)\n",
    "                    y = int(lm.y * CAP_HEIGHT)\n",
    "                    if 0 <= x < CAP_WIDTH and 0 <= y < CAP_HEIGHT:\n",
    "                        frame_map[y, x] = 255  # one pixel for one landmark on 2D frame\n",
    "                \n",
    "                # Save frame_map\n",
    "                filename = os.path.join(SAVE_DIR, f\"cell_{row}_{col}_{int(time.time()*1000)}.npy\")\n",
    "                np.save(filename, frame_map)\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4bea00-5147-4c1e-9bc1-03bed4b77e38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
